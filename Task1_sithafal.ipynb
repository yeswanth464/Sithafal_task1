{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/dEPgZMWVMJXWVpxbq2qo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeswanth464/Sithafal_task1/blob/main/Task1_sithafal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejkkGOUxd8c1",
        "outputId": "5b76f4e2-95e9-41b4-ea58-baa4689a33a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mvFDWwR7eDK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDzGrb6heDp1",
        "outputId": "6ee91245-ec8c-481b-ac28-51dc9d6f1bc1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpXIjTv6eLGv",
        "outputId": "636413c2-4218-43b8-80f7-eda7cedff5c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI7KlJo3WHim",
        "outputId": "35e6e583-b0ce-4c4a-aaa4-1c6a482d0e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 1: Context: 29 In essence, the internship at YBI Foundation has been a holistic and well -rounded journey. It has deepened my knowledge base, honed my technical skills, and provided a glimpse into the collaborative and dynamic world of computer science. As I conclude this transformative experience, I carry forward not just a certificate of completion but a comprehensive set of skills, perspectives, and a passion for continuous learning in the ever -evolving field of technology.\n",
            "26 D. Optimization Techniques A crucial aspect of the internship was the exploration of optimization techniques. Understanding how to judiciously select and use data structures contributed to writing efficient and scalable code. The emphasis on constraint propagation and forward checking provided insights into enhancing program efficiency. E. Collaborative Learning Environment The internship fostered a collaborative learning environment, encouraging teamwork on practical projects. Engaging with peers, sharing insights, and collectively tackling coding challenges enhanced my ability to work collaboratively, mirroring real -world software development scenarios. F. Professional Guidance Under the esteemed supervision of Dr. G. Sunitha, a seasoned professor in the Department of Computer Science and Engineering, I received valuable guidance and mentorship. The support extende d by the faculty contributed significantly to my learning experience.\n",
            "27 CHAPTER 3 REFLECTION ON LEARNING Reflecting on the internship, I recognize the substantial growth in my understanding of data structures and algorithmic problem -solving. The hands -on projects, especially the Sudoku solver, provided a tangible application of theoretical knowledge. A. Key Takeaways Practical Implementation: The internship emphasized the importance of practical implementation in reinforcing theoretical concepts. Building solutions to real -world problems deepened my understanding of data structures. • Python as a Tool: The choice of Python as the primary programming language showcased its effectiveness in implementing data structures. The language's simplicity and readability proved instrumental in rapid development. • Optimization Mindset: Learning optimization techniques underscored the significance of making informed decisions about data structures. Evaluating trade -offs and choosing the right structures contributed to efficient code. B. Future Applications The skills acquired during the internship lay a strong foundation for future endeavors. The ability to apply data structures in problem -solving scenarios and the proficiency gained in Python programming are transferable skills applicable across diverse domains. C. Recommendations I recommend incorporating more industry -oriented projects in future internships, providing exposure to real -world challenges. Additionally, integrating coding competitions or challenges could further enhance problem -solving skills and competitiveness among interns.\n",
            "\n",
            "Query: What is the internship?\n",
            "\n",
            "Answer: An internship helps create new knowledge. While this is an interesting avenue, it is not an exclusive one. Internships are not exclusively for computer science majors, though; they also provide valuable networking opportunities for students in general. The internships of a few college departments and universities offer a variety of opportunities for students to learn more about software development, software engineering, and machine learning and machine learning. A strong need for a professional development mindset is a major motivation for developing your programming skills and understanding of how things\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 2: Context: vii Abbreviations • YBI: Yanthra Byte Internships Foundation • Edutech : Educational Technology • IDE: Integrated Development Environment • CI/CD: Continuous Integration/Continuous Deployment • SQL: Structured Query Language • HTML: Hypertext Markup Language • CSS: Cascading Style Sheets • API: Application Programming Interface • Git: Version Control System • GUI : Graphical User Interface • PDF: Portable Document Format • PNG: Portable Network Graphics • JPEG: Joint Photographic Experts Group • SVG: Scalable Vector Graphics • RAM: Random Access Memory • P&P algorithm: Paper and Pen algorithm\n",
            "24 XIII. Database (if applicable) A. Database Systems: • SQLite, MySQL, or PostgreSQL: Depending on project requirements, a database system might have been integrated. XIV. Continuous Integration/Continuous Deployment (CI/CD) A. CI/CD Tools: • Jenkins, Travis CI, or GitLab CI: These tools automate the testing and deployment process, ensuring a streamlined development pipeline. This technology stack reflects the tools and technologies that might have been employed during the internship, particularly for the Sudoku Solver Project. The specific tools and versions may vary based on individual preferences and project requirements.\n",
            "22 IV. Version Control A. Git:Git was used for version control, enabling collaborative development, tracking changes, and managing project history. V. Documentation A. Markdown: Markdown was employed for creating structured and easily readable documentation. It supports text formatting and can be converted to various formats. VI. Collaboration and Communication A.Communication Tools: • Email: Used for formal communication, submitting reports, and receiving feedback. • Instant Messaging: Platforms like Slack or Microsoft Teams may have been used for real-time communication within the team. VII. Presentation A. Presentation Tools: • Microsoft PowerPoint or Google Slides : Likely used for creating presentations summarizing the internship experience, project details, and learnings. VIII. Project Management A. Project Management Tools: • Trello, Asana, or Jira: These tools help in organizing tasks, tracking progress, and managing the overall project workflow.\n",
            "\n",
            "Query: What is GUI?\n",
            "\n",
            "Answer: Guessing what is GUI is the process for solving problems. The GUI is an application interface that helps developers develop software. The GUI provides the framework for writing and executing code. The GUI also provides the functionality to connect to an external database. The GUI is also an integrated development experience that allows for collaboration among different teams or individuals. The GUI is used for the creation of projects, team-based projects, meetings, development, and production systems. The GUI has been widely used and has made a huge\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import PyPDF2\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
        "import numpy as np\n",
        "\n",
        "# Load API key from environment variable\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the embedding model\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Ensure pad_token is set if not already\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Set eos_token as pad_token\n",
        "\n",
        "# Function to generate sentence embeddings\n",
        "def encode_text(text):\n",
        "    # Tokenize the input text, set padding=True to automatically pad the sequence\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        return_attention_mask=True\n",
        "    )\n",
        "\n",
        "    # Get the model output (embedding) and return the mean of the last hidden state\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Return the embeddings by averaging the last hidden states\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "    return embeddings.flatten()  # Ensure embedding is a 1D array\n",
        "\n",
        "# List to store chunks and their metadata\n",
        "chunk_store = []\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text_chunks = []\n",
        "    for page in pdf_reader.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            text_chunks.append(text)\n",
        "    return text_chunks\n",
        "\n",
        "# Function to chunk text into smaller parts\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Function to create embeddings and store them in the chunk_store\n",
        "def create_embeddings_and_store(pdf_chunks, metadata):\n",
        "    for chunk in pdf_chunks:\n",
        "        embedding = encode_text(chunk)\n",
        "        chunk_store.append({\"embedding\": embedding, \"text\": chunk, \"metadata\": metadata})\n",
        "\n",
        "# Function to retrieve relevant chunks based on a user query\n",
        "def retrieve_relevant_chunks(query, top_k=3):\n",
        "    query_embedding = encode_text(query)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarities = [\n",
        "        np.dot(query_embedding, entry[\"embedding\"]) / (\n",
        "            np.linalg.norm(query_embedding) * np.linalg.norm(entry[\"embedding\"])\n",
        "        ) for entry in chunk_store\n",
        "    ]\n",
        "\n",
        "    sorted_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "    results = [chunk_store[idx] for idx in sorted_indices]\n",
        "    return results\n",
        "\n",
        "# Function to generate a response using a local Hugging Face model (e.g., GPT-2)\n",
        "def generate_response(relevant_chunks, query):\n",
        "    model_name = \"gpt2\"  # Replace with a better model if needed\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    # Prepare the input context and query\n",
        "    context = \"\\n\".join([chunk['text'] for chunk in relevant_chunks])\n",
        "    prompt = f\"Context: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "\n",
        "    # Generate the response with adjusted max_new_tokens and higher temperature for diversity\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_new_tokens=100,  # Limiting new tokens to avoid overly long output\n",
        "        num_return_sequences=1,\n",
        "        temperature=1.0,  # Increase randomness\n",
        "        top_p=0.95,  # Use nucleus sampling for more variability\n",
        "        do_sample=True,  # Enable sampling for randomness\n",
        "    )\n",
        "\n",
        "    # Decode and return the response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Example: Processing a PDF and handling queries\n",
        "pdf_path = \"/content/yyr report.pdf\"  # Replace with your PDF file\n",
        "pdf_chunks = []\n",
        "\n",
        "# Extract text from the PDF and chunk it\n",
        "text_data = extract_text_from_pdf(pdf_path)\n",
        "for page_text in text_data:\n",
        "    pdf_chunks.extend(chunk_text(page_text))\n",
        "\n",
        "# Store embeddings in the list\n",
        "metadata = {\"source\": pdf_path}\n",
        "create_embeddings_and_store(pdf_chunks, metadata)\n",
        "\n",
        "# Example queries\n",
        "query_1 = \"What is the internship?\"\n",
        "relevant_chunks_1 = retrieve_relevant_chunks(query_1)\n",
        "response_1 = generate_response(relevant_chunks_1, query_1)\n",
        "print(\"Response 1:\", response_1)\n",
        "\n",
        "query_2 = \"What is GUI?\"\n",
        "relevant_chunks_2 = retrieve_relevant_chunks(query_2)\n",
        "response_2 = generate_response(relevant_chunks_2, query_2)\n",
        "print(\"Response 2:\", response_2)\n"
      ]
    }
  ]
}